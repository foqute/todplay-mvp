# backend/main.py
import os, base64, json, traceback
from pathlib import Path
from typing import Optional, List, Dict, Any

from fastapi import FastAPI, UploadFile, File, Form, Body, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from openai import OpenAI

# ======================
# ì´ˆê¸° ë¡œë“œ & í´ë¼ì´ì–¸íŠ¸
# ======================
load_dotenv()
client = OpenAI()

app = FastAPI(title="TOD play - GPT5 wired", version="0.1.0")

app.add_middleware(
    CORSMiddleware(
        allow_origins=["*"],     # ê°œë°œ ë‹¨ê³„ ì „ì²´ í—ˆìš©
        allow_methods=["*"],
        allow_headers=["*"],
    )
)

# ===== In-memory context store =====
CTX: Dict[str, Dict[str, Any]] = {}

# =====================
# ê¸°ë³¸ ìœ í‹¸ í•¨ìˆ˜
# =====================
def to_data_url(file: UploadFile) -> str:
    raw = file.file.read()
    file.file.seek(0)
    mime = file.content_type or "image/jpeg"
    b64 = base64.b64encode(raw).decode("utf-8")
    return f"data:{mime};base64,{b64}"

def pick_model(user_mode: str) -> str:
    # í•„ìš”í•˜ë©´ ëª¨ë“œë³„ë¡œ ë¶„ê¸°
    return "gpt-5"

# =====================
# í”„ë¡¬í”„íŠ¸
# =====================
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•™ìƒì—ê²Œ ì¹œì ˆí•˜ê³  ê²©ë ¤ë¥¼ ì•„ë¼ì§€ ì•ŠëŠ” ë¯¸ìˆ  ê³¼ì™¸ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
- ì¶œë ¥ì€ í•œêµ­ì–´.
- ë§ˆí¬ë‹¤ìš´ ì„¹ì…˜ê³¼ ë²ˆí˜¸ ëª©ë¡ì„ ì ê·¹ ì‚¬ìš©.
- 'ë¹ ë¥¸ ìš”ì•½' â†’ 'í˜•íƒœ/ë¹„ìœ¨' â†’ 'êµ¬ë„/ì›ê·¼' â†’ 'ì¸ì²´/ì†ë°œ' â†’ 'ì„ /ë°¸ë¥˜/ì—ì§€' â†’ 'ì±„ìƒ‰/ìŒì˜'(ìˆì„ ë•Œ) â†’
  'ì˜¤ë²„ë ˆì´ ê´€ì°° í¬ì¸íŠ¸' â†’ '30ì´ˆ ë“œë¦´ 3ê°œ' â†’ 'ìš°ì„ ìˆœìœ„ Top 3' â†’ 'ì‘ì›ì˜ ë©˜íŠ¸' ìˆœì„œ.
- ê° í•­ëª©ì€ 1~2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ. ë§íˆ¬ëŠ” ë¶€ë“œëŸ½ê³  ë™ê¸°ë¶€ì—¬ê°€ ë˜ê²Œ.
"""

CHAT_SYSTEM = """ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ëŠ” ê·¸ë¦¼ í•™ìŠµ ì¡°êµì…ë‹ˆë‹¤.
- ì§§ê³  ëª…í™•í•˜ê²Œ ë‹µí•˜ê³ , í•„ìš”í•˜ë©´ ë‹¨ê³„ë³„ íŒì„ 1~3ê°œ ë¶ˆë¦¿ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
- ì‘í’ˆ ë¶„ì„/ì—°ìŠµë²•/ë„êµ¬ í™œìš©/í•´ë¶€í•™/ì›ê·¼/ì±„ìƒ‰ ë“± ë¯¸ìˆ  ì „ë°˜ ì§ˆë¬¸ì— ë‹µí•©ë‹ˆë‹¤.
- ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ì˜ ì›ì‘/ì‹¤ìŠµ ì´ë¯¸ì§€ë¥¼ ìš°ì„  ì°¸ê³ í•´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
"""

# =====================
# ìœ í‹¸: metrics íŒŒì‹±/ë¼ë²¨
# =====================
_METRIC_LABELS = {
    "shape": "í˜•íƒœ",
    "value": "ëª…ì•”",
    "color": "ìƒ‰ê°",
    "edge":  "íˆ¬ì‹œ",
    "persp": "íˆ¬ì‹œ",
    "structure": "êµ¬ë„",
    "comp": "êµ¬ë„",
    # í•„ìš”ì‹œ ì“¸ ìˆ˜ ìˆëŠ” ë””í…Œì¼/ì™„ì„±ë„ ì½”ë“œ
    "detail": "ë””í…Œì¼/ì™„ì„±ë„",
}
def parse_metrics(metrics: Optional[str]) -> List[str]:
    if not metrics:
        return []
    try:
        arr = json.loads(metrics)
        if isinstance(arr, list):
            return [str(x) for x in arr]
    except Exception:
        pass
    return []

def ko_metrics_list(metrics_codes: List[str]) -> str:
    if not metrics_codes:
        return "í˜•íƒœ ì¤‘ì‹¬"
    names = [_METRIC_LABELS.get(k, k) for k in metrics_codes]
    return ", ".join(names)

# =====================
# í—¬ìŠ¤ ì²´í¬
# =====================
@app.get("/ping")
def ping():
    return {"ok": True}

# ==========================
# /analyze â€” í”¼ë“œë°± ë¶„ì„ (TOD í”Œë ˆì´)
# ==========================
@app.post("/analyze")
async def analyze(
    left: UploadFile = File(...),
    right: UploadFile = File(...),
    mode: str = Form("AUTO"),
    metrics: Optional[str] = Form(None),
    learn: str = Form("ëª¨ì‘"),
    hints: Optional[str] = Form(None),
    context_id: Optional[str] = Form(None),
    client_ts: Optional[str] = Form(None),
    question: Optional[str] = Form(None),
):
    try:
        print("[ANALYZE] ìš”ì²­ ìˆ˜ì‹ ", flush=True)
        print(f"[ANALYZE] mode={mode}, learn={learn}, metrics={metrics}, context_id={context_id}", flush=True)

        model = pick_model(mode)
        left_url  = to_data_url(left)
        right_url = to_data_url(right)
        print(f"[ANALYZE] left_url_len={len(left_url)}, right_url_len={len(right_url)}", flush=True)

        metric_codes = parse_metrics(metrics)
        metric_ko = ko_metrics_list(metric_codes)
        print(f"[ANALYZE] metric_ko={metric_ko}", flush=True)

        mode_policy = (
            "FAST ëª¨ë“œ: 'í˜•íƒœ' ë˜ëŠ” 'í˜•íƒœ+ëª…ì•”'ë§Œ ê°„ë‹¨ í‰ê°€.\n"
            "FULL ëª¨ë“œ: í˜•íƒœ/ëª…ì•”/ìƒ‰ê°/íˆ¬ì‹œ/êµ¬ë„ë¥¼ ëª¨ë‘ í‰ê°€.\n"
            "ì²´í¬ëœ í•­ëª©ë§Œ ë‹¤ë£¨ë˜, í•µì‹¬ë§Œ ê°„ê²°íˆ."
        )

        if learn == "ì°½ì‘":
            base_text = (
                "ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ëŠ” 'ì‹¤ìŠµ'ì…ë‹ˆë‹¤. ì´ ì´ë¯¸ì§€ë§Œ ë‹¨ë…ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”. "
                f"í‰ê°€ í•­ëª©: {metric_ko}. " + mode_policy
            )
            content_images = [{"type": "input_image", "image_url": right_url}]
        elif learn == "ìŠ¤íƒ€ì¼ ëª¨ì‘":
            base_text = (
                "ì™¼ìª½ì€ ë ˆí¼ëŸ°ìŠ¤(ìŠ¤íƒ€ì¼), ì˜¤ë¥¸ìª½ì€ 'ì‹¤ìŠµ'ì…ë‹ˆë‹¤. "
                f"í‰ê°€ í•­ëª©: {metric_ko}. " + mode_policy
            )
            content_images = [
                {"type": "input_image", "image_url": left_url},
                {"type": "input_image", "image_url": right_url},
            ]
        else:
            base_text = (
                "ì™¼ìª½ì€ 'ì›ë³¸', ì˜¤ë¥¸ìª½ì€ 'ì‹¤ìŠµ'ì…ë‹ˆë‹¤. "
                f"í‰ê°€ í•­ëª©: {metric_ko}. " + mode_policy
            )
            content_images = [
                {"type": "input_image", "image_url": left_url},
                {"type": "input_image", "image_url": right_url},
            ]

        # (ì—¬ê¸°ì„œëŠ” ë””í…Œì¼ ì§€ì¹¨ì€ ì¶”ê°€í•˜ì§€ ì•ŠìŒ â€” ì˜¤ëŠ˜ì˜ ë¯¸ì…˜ ìª½ì—ì„œ ì ìˆ˜ë¡œ ë°˜ì˜)

        if question:
            base_text += "\n\ní•™ìƒ ì§ˆë¬¸: " + question.strip()
        if hints:
            try:
                base_text += "\n\nì¶”ê°€ ì§€ì¹¨:\n" + json.dumps(
                    json.loads(hints), ensure_ascii=False, indent=2
                )
            except Exception:
                base_text += "\n\nì¶”ê°€ ì§€ì¹¨:\n" + str(hints)

        print(f"[ANALYZE] OpenAI í˜¸ì¶œ ì‹œì‘ - model={model}", flush=True)
        resp = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": SYSTEM_PROMPT}]},
                {"role": "user", "content": [{"type": "input_text", "text": base_text}, *content_images]},
            ],
        )
        print("[ANALYZE] OpenAI ì‘ë‹µ ìˆ˜ì‹ ", flush=True)

        notes_text = resp.output_text
        print(f"[ANALYZE] ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸¸ì´={len(notes_text)}", flush=True)

        feedback_plain = "\n".join(
            line.replace("#", "").strip() for line in notes_text.splitlines()
        ).strip()
        cid = context_id or "default"
        CTX[cid] = {
            "left_image": left_url,
            "right_image": right_url,
            "feedback_text": feedback_plain,
            "learn": learn,
            "metric_codes": metric_codes,
            "last_mode": mode,
        }

        print(f"[ANALYZE] ì»¨í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ cid={cid}", flush=True)
        return {"ok": True, "notes": notes_text, "context_id": cid}
    except Exception as e:
        print("[ANALYZE][ERROR]", repr(e), flush=True)
        traceback.print_exc()
        return {"ok": False, "error": f"{type(e).__name__}: {e}"}

# ==========================
# /chat â€” ë¬¸ë§¥ Q/A
# ==========================
class ChatIn(BaseModel):
    message: str
    mode: Optional[str] = "AUTO"
    context_id: Optional[str] = None
    feedback_text: Optional[str] = ""
    learn: Optional[str] = ""
    metrics_map: Optional[Dict[str, Any]] = None
    left_image: Optional[str] = None
    right_image: Optional[str] = None
    client_ts: Optional[int] = None

@app.post("/chat")
async def chat(inp: ChatIn):
    try:
        msg = (inp.message or "").strip()
        if not msg:
            return {"ok": False, "reply": "ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."}
        cid = inp.context_id or "default"
        cached = CTX.get(cid, {})
        left  = inp.left_image  or cached.get("left_image")
        right = inp.right_image or cached.get("right_image")
        fb    = (inp.feedback_text or "").strip() or cached.get("feedback_text", "")
        learn = inp.learn or cached.get("learn", "")
        metric_codes = cached.get("metric_codes", [])
        if not (left and right):
            return {"ok": True, "reply": "ì›ì‘/ì‹¤ìŠµ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”."}

        user_blocks = []
        ctx_summary = [
            f"[ì„¸ì…˜] {cid}",
            f"[í•™ìŠµìœ í˜•] {learn or 'ëª¨ì‘'}",
            f"[í‰ê°€í•­ëª©] {ko_metrics_list(metric_codes)}",
        ]
        if fb:
            ctx_summary.append(f"[í”¼ë“œë°±]\n{fb[:600]}{'...' if len(fb) > 600 else ''}")
        user_blocks.append({"type": "input_text", "text": "\n".join(ctx_summary)})
        user_blocks.append({"type": "input_image", "image_url": left})
        user_blocks.append({"type": "input_image", "image_url": right})
        user_blocks.append({"type": "input_text", "text": msg})

        model = pick_model(inp.mode)
        resp = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": CHAT_SYSTEM}]},
                {"role": "user", "content": user_blocks},
            ],
        )
        reply = resp.output_text
        CTX.setdefault(cid, {})["last_chat"] = msg
        return {"ok": True, "reply": reply}
    except Exception as e:
        return {"ok": False, "reply": "ì˜¤ë¥˜ ë°œìƒ", "error": str(e)}

# ==========================
# ğŸŸ¢ ì˜¤ëŠ˜ì˜ ë“œë¡œì‰ ë¯¸ì…˜ ê´€ë¦¬
# ==========================
ROOT = Path(__file__).resolve().parents[1]  # backend/.. = í”„ë¡œì íŠ¸ ë£¨íŠ¸
MISSION_DIR = ROOT / "missions"
MISSION_DIR.mkdir(parents=True, exist_ok=True)
MISSION_FILE = MISSION_DIR / "daily_missions.json"

# ì •ì  íŒŒì¼ ì œê³µ(/missions/daily_missions.json)
app.mount("/missions", StaticFiles(directory=str(MISSION_DIR)), name="missions")

class MissionUpsert(BaseModel):
    date: str         # "YYYY-MM-DD"
    title: str = ""   # ì˜µì…˜
    images: list      # dataURL ë°°ì—´

def _read_json() -> Dict[str, Any]:
    if not MISSION_FILE.exists():
        return {}
    try:
        return json.loads(MISSION_FILE.read_text("utf-8"))
    except Exception:
        return {}

def _write_json(data: Dict[str, Any]):
    MISSION_FILE.write_text(
        json.dumps(data, ensure_ascii=False, indent=2), "utf-8"
    )

# ---- ìƒˆ(ê¶Œì¥) ê²½ë¡œ: /api/missions/daily_missions ----
@app.post("/api/missions/daily_missions")
@app.put("/api/missions/daily_missions")
def upsert_daily_mission_api(payload: MissionUpsert = Body(...)):
    if not payload.images or not isinstance(payload.images, list):
        raise HTTPException(status_code=400, detail="images must be a list")
    data = _read_json()
    data[payload.date] = {"title": payload.title, "images": payload.images}
    _write_json(data)
    return {"ok": True, "saved": payload.date}

# ---- ë ˆê±°ì‹œ ê²½ë¡œ: /missions/daily_missions (POST/PUT ë‘˜ ë‹¤ í—ˆìš©) ----
@app.post("/missions/daily_missions")
@app.put("/missions/daily_missions")
def upsert_daily_mission_legacy(payload: MissionUpsert = Body(...)):
    return upsert_daily_mission_api(payload)

# ---- ì¡°íšŒ ----
@app.get("/missions/daily_missions.json")
def read_missions():
    return _read_json()

# ==========================
# ğŸŸ¢ ìœ ì‚¬ë„ í‰ê°€ (FAST) â€” ì˜¤ëŠ˜ì˜ ë“œë¡œì‰ ë¯¸ì…˜ìš©
# ==========================
from io import BytesIO
import re
import numpy as np
from PIL import Image
from skimage.metrics import structural_similarity as ssim
import cv2


def _decode_data_url(data_url: str) -> Image.Image:
    # data:[mime];base64,....
    m = re.match(r"^data:.*?;base64,(.+)$", data_url)
    if not m:
        raise HTTPException(400, "Invalid dataURL")
    raw = base64.b64decode(m.group(1))
    return Image.open(BytesIO(raw)).convert("RGB")


def _to_gray_np(im: Image.Image) -> np.ndarray:
    return cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)


def _phash(im: Image.Image) -> int:
    # ê°„ë‹¨ pHash (ì „ì²´ ì‹¤ë£¨ì—£/í†¤)
    im_small = im.resize((32, 32), Image.LANCZOS).convert("L")
    a = np.array(im_small, dtype=np.float32)
    dct = cv2.dct(a)
    dctlow = dct[:8, :8]
    med = np.median(dctlow)
    bits = (dctlow > med).flatten()
    val = 0
    for b in bits:
        val = (val << 1) | int(b)
    return int(val)


def _hamming(a: int, b: int) -> int:
    return (a ^ b).bit_count()


def _orb_match_score(imgA_g: np.ndarray, imgB_g: np.ndarray) -> int:
    # ì—£ì§€/ë””í…Œì¼ ìœ„ì£¼ì˜ íŠ¹ì§• ë§¤ì¹­
    orb = cv2.ORB_create()
    kp1, des1 = orb.detectAndCompute(imgA_g, None)
    kp2, des2 = orb.detectAndCompute(imgB_g, None)
    if des1 is None or des2 is None:
        return 0
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)
    matches = sorted(matches, key=lambda m: m.distance)
    # ìƒìœ„ 50ê°œ ë§¤ì¹˜ ìˆ˜/í’ˆì§ˆì„ ì ìˆ˜í™”
    top = matches[:50]
    score = sum(max(0, 256 - m.distance) for m in top) // max(1, len(top))
    return int(score)


class SimilarityIn(BaseModel):
    ref: str   # dataURL (ì›ì‘/ì¢Œì¸¡)
    test: str  # dataURL (ì‹¤ìŠµ/ìš°ì¸¡)


@app.post("/similarity/compare")
def similarity_compare(inp: SimilarityIn):
    try:
        # 1) dataURL â†’ PIL ì´ë¯¸ì§€
        A = _decode_data_url(inp.ref)
        B = _decode_data_url(inp.test)

        # 2) í¬ê¸° ë³´ì •(SSIM ë¹„êµë¥¼ ìœ„í•´ ë™ì¼ í¬ê¸°)
        W = min(A.width, B.width)
        H = min(A.height, B.height)
        A2 = A.resize((W, H), Image.LANCZOS)
        B2 = B.resize((W, H), Image.LANCZOS)

        # 3) ê·¸ë ˆì´ìŠ¤ì¼€ì¼
        gA = _to_gray_np(A2)
        gB = _to_gray_np(B2)

        #    3-1) ê¸°ë³¸ SSIM (í˜•íƒœ/í†¤ ì¤‘ì‹¬)
        ssim_val = float(ssim(gA, gB, data_range=255))

        #    3-2) ì—£ì§€ SSIM (ìœ¤ê³½ì„ /ë””í…Œì¼ ì¤‘ì‹¬)
        edgesA = cv2.Canny(gA, 50, 150)
        edgesB = cv2.Canny(gB, 50, 150)
        edge_ssim = float(ssim(edgesA, edgesB, data_range=255))

        #    3-3) pHash / ORB
        ph_a = _phash(A2)
        ph_b = _phash(B2)
        ph_dist = _hamming(ph_a, ph_b)

        orb_score = _orb_match_score(gA, gB)

        # 4) 0~100 ì ìˆ˜ ê³„ì‚°
        #    í˜•íƒœ(SSIM) + ë””í…Œì¼(edge SSIM + ORB) ë¹„ì¤‘ì„ ë†’ê²Œ ì„¤ì •
        sim_raw = (
            ssim_val * 60.0                          # ì „ì²´ í˜•íƒœ/í†¤
            + edge_ssim * 25.0                       # ìœ¤ê³½ì„ Â·ë””í…Œì¼ ìœ ì‚¬ë„
            + max(0.0, 1.0 - ph_dist / 64.0) * 8.0   # ì „ì²´ ì‹¤ë£¨ì—£
            + min(1.0, orb_score / 200.0) * 7.0      # ì„¸ë¶€ íŠ¹ì§• ë§¤ì¹­
        )

        # 5) 0~1 ì‚¬ì´ë¡œ ì •ê·œí™” í›„ ê°ë§ˆ ë³´ì •
        sim01 = max(0.0, min(1.0, sim_raw / 100.0))
        sim_boosted = sim01 ** 0.7  # 0.8â†’0.86, 0.9â†’0.93, 1.0â†’1.0
        sim_pct = int(round(sim_boosted * 100))

        return {
            "ok": True,
            "ssim": round(ssim_val, 4),
            "edge_ssim": round(edge_ssim, 4),
            "phash_distance": ph_dist,
            "orb_score": orb_score,
            "similarity_pct": sim_pct,
        }
    except Exception as e:
        raise HTTPException(400, f"similarity error: {e}")
